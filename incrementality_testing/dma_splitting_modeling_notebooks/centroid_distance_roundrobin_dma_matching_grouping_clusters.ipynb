{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_df = pd.read_csv('/Users/jacob.perius/psa_segment_testing/11_4_24_CustomerData_20241104_000000000000.csv', low_memory=False)\n",
    "\n",
    "customer_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(customer_df.columns)\n",
    "\n",
    "customer_df = customer_df[customer_df['latest_order_date'] > '2024-01-01']\n",
    "\n",
    "customer_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_df['segment'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_df['submission_count'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "customer_df.loc[:, 'zip_code'] = customer_df.loc[:, 'zip_code'].str.split('-').str[0]\n",
    "customer_df.loc[:, 'zip_code'] = customer_df.loc[:, 'zip_code'].apply(lambda x: np.nan if x == 'nan' else x)\n",
    "\n",
    "customer_df = customer_df[customer_df['zip_code'].notna() & (customer_df['zip_code'] != '')]\n",
    "\n",
    "customer_df = customer_df[~customer_df['zip_code'].str.contains('@')]\n",
    "customer_df.loc[:, 'zip_code'] = customer_df.loc[:, 'zip_code'].str.strip(\"'\")\n",
    "customer_df.loc[:, 'zip_code'] = customer_df.loc[:, 'zip_code'].apply(lambda x: re.sub(r'\\D', '', str(x)))\n",
    "customer_df = customer_df[customer_df['zip_code'] != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_df['zip_code'] = customer_df['zip_code'].str.zfill(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dma_df = pd.read_csv('/Users/jacob.perius/psa_segment_testing/ENV _ Census _ ZIP to DMA.csv')\n",
    "\n",
    "dma_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dma_df['zip_code'] = dma_df['zip_code'].astype('str').str.zfill(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(customer_df, dma_df, on='zip_code', how='left')\n",
    "\n",
    "merged_df.drop(columns=['date_updated_at'], inplace=True)\n",
    "\n",
    "merged_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_counts_df = merged_df.groupby(['dma_code', 'dma_description']).size().reset_index(name='count')\n",
    "\n",
    "group_counts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = merged_df.groupby(['dma_code', 'dma_description']).agg({\n",
    "    'submission_count': 'sum',\n",
    "    'submission_total_qty': 'sum',\n",
    "    'submission_total_dv': 'sum',\n",
    "    'avg_dv_per_sub': 'mean',\n",
    "    'avg_item_per_sub': 'mean',\n",
    "    'total_orders': 'sum',\n",
    "    'total_qty_ordered': 'sum',\n",
    "    'total_order_revenue': 'sum',\n",
    "    'submission_count_2023': 'sum',\n",
    "    'submission_total_qty_2023': 'sum',\n",
    "    'submission_total_dv_2023': 'sum',\n",
    "    'total_orders_2023': 'sum',\n",
    "    'total_qty_ordered_2023': 'sum',\n",
    "    'total_order_revenue_2023': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "grouped_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.merge(grouped_df, group_counts_df, on=['dma_code', 'dma_description'], how='left')\n",
    "\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_df = pd.read_csv('/Users/jacob.perius/psa_segment_testing/zip_grouped_census_df.csv')\n",
    "\n",
    "population_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.merge(final_df, population_df, on='dma_code', how='left')\n",
    "\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_cols = [\n",
    "    col for col in final_df.columns\n",
    "    if col not in ['dma_code', 'dma_description', 'population'] \n",
    "    and not any(keyword in col for keyword in ['normalized', 'avg'])\n",
    "]\n",
    "new_cols = [f'population_normalized_{col}' for col in old_cols]\n",
    "\n",
    "final_df[new_cols] = final_df[old_cols].div(final_df['population'], axis=0)\n",
    "\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_cols2 = [\n",
    "    col for col in final_df.columns\n",
    "    if col not in ['dma_code', 'dma_description', 'population', 'count'] \n",
    "    and not any(keyword in col for keyword in ['normalized', 'avg'])\n",
    "]\n",
    "new_cols2 = [f'intra_dma_avg_{col}' for col in old_cols2]\n",
    "\n",
    "final_df[new_cols2] = final_df[old_cols2].div(final_df['count'], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_cols3 = [\n",
    "    col for col in final_df.columns\n",
    "    if col not in ['dma_code', 'dma_description', 'population'] \n",
    "    and not any(keyword in col for keyword in ['normalized', 'avg'])\n",
    "]\n",
    "new_cols3 = [f'percent_of_total_{col}' for col in old_cols3]\n",
    "\n",
    "final_df[new_cols3] = final_df[old_cols3].apply(lambda x: x / x.sum(), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = final_df.drop(columns=old_cols2)\n",
    "\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "google_data_df = pd.read_csv('/Users/jacob.perius/psa_segment_testing/google_ads_data.csv')\n",
    "google_data_df = google_data_df.iloc[:-6]\n",
    "\n",
    "google_data_df['zip_code'] = google_data_df['Matched location'].apply(lambda x: re.search(r'^\\d{5}', x).group(0))\n",
    "google_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_data_df['Impr.'] = google_data_df['Impr.'].str.replace(',', '').str.strip().astype('int64')\n",
    "google_data_df['Clicks'] = google_data_df['Clicks'].str.replace(',', '').str.strip().astype('int64')\n",
    "google_data_df['cvr'] = google_data_df['Clicks'] / google_data_df['Impr.']\n",
    "google_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_dma_df = pd.merge(google_data_df, dma_df, on='zip_code', how='right')[['dma_code', 'dma_description', 'cvr']]\n",
    "\n",
    "google_dma_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_google_dma_df = google_dma_df.groupby(['dma_code', 'dma_description']).mean().reset_index()\n",
    "\n",
    "grouped_google_dma_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df_with_cvr = pd.merge(final_df, grouped_google_dma_df, on=['dma_code', 'dma_description'], how='left')\n",
    "\n",
    "final_df_with_cvr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#features = final_df_with_cvr.iloc[:, 2:]\n",
    "\n",
    "relevant_features = [\n",
    "    feature for feature in final_df_with_cvr.iloc[:, 2:].columns\n",
    "    if (('intra' in feature) or (feature =='cvr')) and ('dv' not in feature) #if ((feature != 'count') and (feature != 'population')\n",
    "]\n",
    "\n",
    "#features = features.drop(columns=['population']) #trying to focus on features that are not population or percent of total\n",
    "features = final_df_with_cvr[relevant_features]\n",
    "\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(features)\n",
    "\n",
    "x_scaled_df =pd.DataFrame(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_scaled_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# min_dist (e.g., to 0.2 or 0.3) might encourage more spread and separation between clusters.\n",
    "\n",
    "from umap import UMAP\n",
    "\n",
    "umap = UMAP(n_components=2, random_state=42, metric='euclidean', n_neighbors=15, min_dist=0.1) #25\n",
    "\n",
    "X_umap = umap.fit_transform(X_scaled)\n",
    "\n",
    "X_pca_df2 = pd.DataFrame(X_umap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pca_df2.rename(columns={0: 'x', 1: 'y', 2: 'z'}, inplace=True)\n",
    "X_pca_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "\n",
    "# Perform clustering on UMAP embeddings\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "cluster_labels = kmeans.fit_predict(X_umap)\n",
    "\n",
    "#agglo = AgglomerativeClustering(n_clusters=3, linkage='ward')\n",
    "#cluster_labels = agglo.fit_predict(X_umap)\n",
    "\n",
    "final_df_with_cvr['cluster'] = cluster_labels\n",
    "final_df_with_cvr['x'], final_df_with_cvr['y'] = X_pca_df2['x'], X_pca_df2['y']\n",
    "\n",
    "final_df_with_cvr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import euclidean\n",
    "\n",
    "centroids = final_df_with_cvr.groupby('cluster')[['x', 'y']].mean()\n",
    "\n",
    "# Calculate the distance of each point to its own cluster's centroid\n",
    "def calculate_distance(row):\n",
    "    cluster_id = row['cluster']\n",
    "    centroid = centroids.loc[cluster_id]\n",
    "    return euclidean((row['x'], row['y']), centroid)\n",
    "\n",
    "final_df_with_cvr['distance_to_centroid'] = final_df_with_cvr.apply(calculate_distance, axis=1)\n",
    "\n",
    "group_assignments = []\n",
    "\n",
    "for cluster_id, group_df in final_df_with_cvr.groupby('cluster'):\n",
    "    # Sort points within the cluster by distance to the centroid\n",
    "    sorted_df = group_df.sort_values(by='distance_to_centroid')\n",
    "    \n",
    "    # Calculate group sizes\n",
    "    count = len(sorted_df)\n",
    "    group_size = count // 3\n",
    "    remainder = count % 3\n",
    "    \n",
    "    # Assign groups based on distance ranking within each cluster\n",
    "    group_labels = ['Group A'] * group_size + ['Group B'] * group_size + ['Group C'] * group_size\n",
    "\n",
    "    # Handle any remainders\n",
    "    for i in range(remainder):\n",
    "        group_labels.append(f'Group {chr(65 + i)}')\n",
    "    \n",
    "    sorted_df['group'] = group_labels\n",
    "    \n",
    "    group_assignments.append(sorted_df)\n",
    "\n",
    "final_df_with_cvr = pd.concat(group_assignments).sort_index()\n",
    "\n",
    "final_df_with_cvr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "import plotly.express as px\n",
    "\n",
    "fig = px.scatter_3d(X_pca_df2, x='x', y='y', z='z', \n",
    "                    color=final_df_with_cvr['cluster'], \n",
    "                    title='DMAs Clustered by UMAP & K-Means',\n",
    "                    opacity=0.7,\n",
    "                    hover_name=final_df_with_cvr['dma_description'],\n",
    "                    labels={'color': 'Cluster'}\n",
    "                    )\n",
    "\n",
    "fig2 = px.scatter_3d(X_pca_df2, x='x', y='y', z='z', \n",
    "                    color=final_df_with_cvr['group'], \n",
    "                    title='DMAs Stratified by Group',\n",
    "                    opacity=0.7,\n",
    "                    hover_name=final_df_with_cvr['dma_description'],\n",
    "                    labels={'color': 'Experiment Group'}\n",
    "                    )\n",
    "\n",
    "fig.show()\n",
    "fig2.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import plotly.express as px\n",
    "\n",
    "fig = px.scatter(X_pca_df2, x='x', y='y', color=final_df_with_cvr['cluster'].astype(str))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import arviz as az\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "import pymc as pm\n",
    "\n",
    "#features_of_interest = final_df_with_cvr.drop(columns=['population', 'count']).columns[3:-2]\n",
    "\n",
    "for feature in relevant_features: #features_of_interest:\n",
    "\n",
    "    data_a = final_df_with_cvr[final_df_with_cvr['group'] == 'Group A'][feature]\n",
    "    data_b = final_df_with_cvr[final_df_with_cvr['group'] == 'Group B'][feature]\n",
    "    data_c = final_df_with_cvr[final_df_with_cvr['group'] == 'Group C'][feature]\n",
    "\n",
    "    with pm.Model() as model:\n",
    "\n",
    "        # Priors for group means and standard deviations\n",
    "        #mu_a = pm.Normal(\"mu_a\", mu=5, sigma=1)\n",
    "        #mu_b = pm.Normal(\"mu_b\", mu=5, sigma=1)\n",
    "        #mu_c = pm.Normal(\"mu_c\", mu=5, sigma=1)\n",
    "\n",
    "        mu_a = pm.Normal(\"mu_a\", mu=0, sigma=100)\n",
    "        mu_b = pm.Normal(\"mu_b\", mu=0, sigma=100)\n",
    "        mu_c = pm.Normal(\"mu_c\", mu=0, sigma=100)\n",
    "\n",
    "        sigma_a = pm.HalfNormal(\"sigma_a\", sigma=1)\n",
    "        sigma_b = pm.HalfNormal(\"sigma_b\", sigma=1)\n",
    "        sigma_c = pm.HalfNormal(\"sigma_c\", sigma=1)\n",
    "\n",
    "        # Likelihoods for observed data\n",
    "        obs_a = pm.Normal(\"obs_a\", mu=mu_a, sigma=sigma_a, observed=data_a)\n",
    "        obs_b = pm.Normal(\"obs_b\", mu=mu_b, sigma=sigma_b, observed=data_b)\n",
    "        obs_c = pm.Normal(\"obs_c\", mu=mu_c, sigma=sigma_c, observed=data_c)\n",
    "\n",
    "        # Sampling\n",
    "        trace = pm.sample(1000, chains=4)\n",
    "\n",
    "    print(trace.posterior)\n",
    "\n",
    "    # Check Posterior Overlap\n",
    "    #pm.plot_posterior(trace, var_names=[\"mu_a\", \"mu_b\", \"mu_c\"])\n",
    "\n",
    "    mu_a_samples = trace.posterior['mu_a'].values.flatten()\n",
    "    mu_b_samples = trace.posterior['mu_b'].values.flatten()\n",
    "    mu_c_samples = trace.posterior['mu_c'].values.flatten()\n",
    "\n",
    "    #hdi_mu_a = az.hdi(mu_a_samples, hdi_prob=0.94)\n",
    "    #hdi_mu_b = az.hdi(mu_b_samples, hdi_prob=0.94)\n",
    "    #hdi_mu_c = az.hdi(mu_c_samples, hdi_prob=0.94)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # Plot KDE for each variable with different colors\n",
    "    sns.kdeplot(mu_a_samples, fill=True, alpha=0.5, label='Group A')\n",
    "    sns.kdeplot(mu_b_samples, fill=True, alpha=0.5, label='Group B')\n",
    "    sns.kdeplot(mu_c_samples, fill=True, alpha=0.5, label='Group C')\n",
    "\n",
    "    plt.xlabel(f\"{feature}\")\n",
    "    plt.ylabel(\"Density\")\n",
    "    plt.title(\"Overlayed Posterior Distributions for Experiment Groups A, B & C\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    #print(f\"Group A {feature} HDI: {hdi_mu_a}\")\n",
    "    #print(f\"Group B {feature} HDI: {hdi_mu_b}\")\n",
    "    #print(f\"Group C {feature} HDI: {hdi_mu_c}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dmas_a = final_df_with_cvr[final_df_with_cvr['group'] == 'Group A']\n",
    "\n",
    "dmas_a.sort_values(by='percent_of_total_submission_count', ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dmas_b = final_df_with_cvr[final_df_with_cvr['group'] == 'Group B']\n",
    "\n",
    "dmas_b.sort_values(by='percent_of_total_submission_count', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dmas_c = final_df_with_cvr[final_df_with_cvr['group'] == 'Group C']\n",
    "\n",
    "dmas_c.sort_values(by='percent_of_total_submission_count', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_and_groups_df = pd.concat([dmas_a, dmas_b, dmas_c], axis=0) #[['group', 'dma_code', 'dma_description']]\n",
    "#names_and_groups_df['dma_code'] = names_and_groups_df['dma_code'].astype('int64')\n",
    "names_and_groups_df['group'] = names_and_groups_df['group'].astype('category')\n",
    "names_and_groups_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#names_and_groups_df.to_csv('names_and_groups.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import plotly.express as px\n",
    "\n",
    "with open('/Users/jacob.perius/psa_segment_testing/neilsen-dma-markets-albers-projection_1356.geojson', 'r') as f:\n",
    "    dma_geojson_str = f.read()\n",
    "\n",
    "# First parse to remove the outer string layer\n",
    "dma_geojson = json.loads(dma_geojson_str)\n",
    "\n",
    "# Second parse if needed (in case it's double-encoded)\n",
    "if isinstance(dma_geojson, str):\n",
    "    dma_geojson = json.loads(dma_geojson)\n",
    "\n",
    "fig = px.choropleth(\n",
    "    names_and_groups_df,\n",
    "    geojson=dma_geojson,\n",
    "    locations='dma_code',\n",
    "    color='group',\n",
    "    featureidkey='properties.dma_code',\n",
    "    color_discrete_map={\n",
    "        'Group A': 'blue',\n",
    "        'Group B': 'orange',\n",
    "        'Group C': 'green'\n",
    "    },\n",
    "    hover_data={'dma_code': True, 'dma_description': True, 'group': True}\n",
    ")\n",
    "\n",
    "fig.update_traces(marker_line_width=1, marker_opacity=1.0)\n",
    "\n",
    "fig.update_geos(\n",
    "    fitbounds=\"locations\",\n",
    "    visible=False,\n",
    ")\n",
    "fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0},\n",
    "                legend_title_text='Test Group'\n",
    "                )\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.write_html('test.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_customers_df = pd.merge(merged_df, names_and_groups_df, on=['dma_code', 'dma_description'], how='left')\n",
    "\n",
    "grouped_customers_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "psa_segment_test_pymc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
