{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/jacob.perius/psa_segment_testing/Incrementality Halfway Analysis/data/data_1_7_24/SubmissionData_20250106_000000000002.csv')\n",
    "\n",
    "print(df.columns)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['is_current_psa_dealer'] == False]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['customer_id', 'submission_id', 'online_completion_date', 'submission_amount_quoted_initial', 'shipping_zipcode', 'submitter_category', 'total_quantity']].copy()\n",
    "df['online_completion_date'] = pd.to_datetime(df['online_completion_date'])\n",
    "df['shipping_zipcode'] = df['shipping_zipcode'].str.split('-').str[0].str.zfill(5)\n",
    "\n",
    "df = df[df['online_completion_date'] >= '2024-11-03'].copy()\n",
    "\n",
    "df['time_post'] = np.where(df['online_completion_date'] <= '2024-12-12', 0, 1)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_to_dma_df = pd.read_csv('/Users/jacob.perius/psa_segment_testing/incrementality_testing/data/ENV _ Census _ ZIP to DMA.csv')\n",
    "zip_to_dma_df['zip_code'] = zip_to_dma_df['zip_code'].astype('str').str.zfill(5)\n",
    "\n",
    "zip_to_dma_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submissions_with_dma = pd.merge(df, zip_to_dma_df, how='left', left_on='shipping_zipcode', right_on='zip_code')\n",
    "submissions_with_dma = submissions_with_dma.drop('zip_code', axis=1)\n",
    "\n",
    "submissions_with_dma.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_df = pd.read_csv('/Users/jacob.perius/psa_segment_testing/incrementality_testing/final_groups/final_groups.csv')\n",
    "\n",
    "group_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submissions_with_group = pd.merge(submissions_with_dma, group_df, how='left', on=['dma_code', 'dma_description'])\n",
    "\n",
    "submissions_with_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_group_df = submissions_with_group.groupby(['online_completion_date', 'time_post', 'group']).agg({\n",
    "    'total_quantity': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "date_group_df['online_completion_date'] = pd.to_datetime(date_group_df['online_completion_date'])\n",
    "\n",
    "date_group_df['dma_split'] = (date_group_df['group'] == 'Group B').astype(int)\n",
    "\n",
    "date_group_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=date_group_df[date_group_df['group'] == 'Group A']['online_completion_date'].to_list(),\n",
    "    y=date_group_df[date_group_df['group'] == 'Group A']['total_quantity'].to_list(),\n",
    "    mode='lines',\n",
    "    name='Group A - Control',\n",
    "    line=dict(width=1, color='blue'),\n",
    "    showlegend=True\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=date_group_df[date_group_df['group'] == 'Group B']['online_completion_date'].to_list(),\n",
    "    y=date_group_df[date_group_df['group'] == 'Group B']['total_quantity'].to_list(),\n",
    "    mode='lines',\n",
    "    name='Group B - Treatment',\n",
    "    line=dict(width=1, color='red'),\n",
    "    showlegend=True\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=['2024-12-12', '2024-12-12'],\n",
    "    y=[min(date_group_df[date_group_df['group'] == 'Group A']['total_quantity']), max(date_group_df[date_group_df['group'] == 'Group B']['total_quantity'].to_list())],\n",
    "    mode='lines',\n",
    "    name='Activation',\n",
    "    line=dict(color='green', dash='dash')\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='PSA Incrementality Test Halfway Analysis (11/3/24 - 1/6/25)',\n",
    "    xaxis_title='Date',\n",
    "    yaxis_title='Total Quantity - Submitted Items',\n",
    "    template='plotly_white',\n",
    "    legend=dict(orientation='v', x=1, xanchor='center'),\n",
    "    width=1300,\n",
    "    height=600\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "#fig.write_html('/Users/jacob.perius/psa_segment_testing/Incrementality Halfway Analysis/PSA Incrementality Halfway Analysis.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seasonality_df = date_group_df.groupby('online_completion_date')['total_quantity'].sum().reset_index(drop=False).copy()\n",
    "seasonality_df = seasonality_df[['online_completion_date', 'total_quantity']].copy()\n",
    "seasonality_df['online_completion_date'] = pd.to_datetime(seasonality_df['online_completion_date'])\n",
    "\n",
    "seasonality_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "decomposition = seasonal_decompose(seasonality_df['total_quantity'], period=7, model='additive')\n",
    "\n",
    "trend = decomposition.trend\n",
    "seasonal = decomposition.seasonal\n",
    "residual = decomposition.resid\n",
    "\n",
    "seasonality_df.loc[:, 'seasonality'] = seasonal\n",
    "\n",
    "date_group_df['dow'] = date_group_df['online_completion_date'].dt.strftime('%A')\n",
    "\n",
    "seasonality_df = pd.merge(\n",
    "    seasonality_df,\n",
    "    date_group_df[['online_completion_date', 'dow']],\n",
    "    on='online_completion_date',\n",
    "    how='left'  # Use 'left' to preserve all rows in seasonality_df\n",
    ")\n",
    "\n",
    "dow_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "seasonality_df['dow'] = pd.Categorical(\n",
    "    seasonality_df['dow'],\n",
    "    categories=dow_order,\n",
    "    ordered=True\n",
    ")\n",
    "\n",
    "print(seasonality_df.shape)\n",
    "seasonality_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_group_df2 = pd.merge(submissions_with_group, seasonality_df.drop('total_quantity', axis=1), how='left', on='online_completion_date')\n",
    "\n",
    "date_group_df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_group_df2['dma_split'] = (date_group_df2['group'] == 'Group B').astype(int)\n",
    "\n",
    "date_group_df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_df = date_group_df2.groupby(['online_completion_date', 'time_post', 'dma_split', 'group', 'submitter_category']).agg({\n",
    "    'seasonality': 'first',\n",
    "    'total_quantity': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "regression_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "before_df = regression_df[regression_df['time_post'] == 0].copy()\n",
    "after_df = regression_df[regression_df['time_post'] == 1].copy()\n",
    "\n",
    "before_sums_df = before_df.groupby('group')['total_quantity'].sum().reset_index()\n",
    "after_sums_df = after_df.groupby('group')['total_quantity'].sum().reset_index()\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    x=before_sums_df[before_sums_df['group'] == 'Group A']['group'].to_list(),\n",
    "    y=before_sums_df[before_sums_df['group'] == 'Group A']['total_quantity'].to_list(),\n",
    "    name='Group A - Control',\n",
    "    marker=dict(color='red', line=dict(width=1)),\n",
    "    showlegend=True\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    x=before_sums_df[before_sums_df['group'] == 'Group B']['group'].to_list(),\n",
    "    y=before_sums_df[before_sums_df['group'] == 'Group B']['total_quantity'].to_list(),\n",
    "    name='Group B - Treated Group',\n",
    "    marker=dict(color='blue', line=dict(width=1)),\n",
    "    showlegend=True\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Incrementality Month Before (11/3/24 - 12/3/24) Submissions',\n",
    "    xaxis_title='Group',\n",
    "    yaxis_title='Submissions',\n",
    "    template='plotly_white',\n",
    "    legend=dict(orientation='v', x=1, xanchor='center'),\n",
    "    width=900,\n",
    "    height=600\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    x=after_sums_df[after_sums_df['group'] == 'Group A']['group'].to_list(),\n",
    "    y=after_sums_df[after_sums_df['group'] == 'Group A']['total_quantity'].to_list(),\n",
    "    name='Group A - Control',\n",
    "    marker=dict(color='red', line=dict(width=1)),\n",
    "    showlegend=True\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    x=after_sums_df[after_sums_df['group'] == 'Group B']['group'].to_list(),\n",
    "    y=after_sums_df[after_sums_df['group'] == 'Group B']['total_quantity'].to_list(),\n",
    "    name='Group B - Treated Group',\n",
    "    marker=dict(color='blue', line=dict(width=1)),\n",
    "    showlegend=True\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Incrementality Month Before (12/3/24 - 1/6/25) Submissions',\n",
    "    xaxis_title='Group',\n",
    "    yaxis_title='Submissions',\n",
    "    template='plotly_white',\n",
    "    legend=dict(orientation='v', x=1, xanchor='center'),\n",
    "    width=900,\n",
    "    height=600\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "platform_spend_data = pd.read_csv('/Users/jacob.perius/psa_segment_testing/Incrementality Halfway Analysis/data/ad_platform_spend.csv')\n",
    "\n",
    "platform_spend_data['Date'] = pd.to_datetime(platform_spend_data['Date'])\n",
    "\n",
    "platform_spend_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_df = pd.merge(regression_df, platform_spend_data, how='left', left_on='online_completion_date', right_on='Date')\n",
    "\n",
    "regression_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "encoder = OneHotEncoder()\n",
    "encoded_array = encoder.fit_transform(regression_df[['submitter_category']]).toarray()\n",
    "submitter_type_one_hot = pd.DataFrame(encoded_array, columns=encoder.get_feature_names_out(['submitter_category']))\n",
    "\n",
    "regression_df = pd.concat([regression_df, submitter_type_one_hot], axis=1)\n",
    "\n",
    "regression_df.columns = regression_df .columns.str.replace(\" \", \"_\")\n",
    "\n",
    "regression_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(regression_df['seasonality'].describe())\n",
    "print(regression_df['seasonality'].isna().sum()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "regression_df[['seasonality', 'Bing_Spend', 'Google_Spend', 'Meta_Spend', 'Reddit_Spend', 'Snapchat_Spend', 'StackAdapt_Spend', 'Tiktok_Spend']] = scaler.fit_transform(regression_df[['seasonality', 'Bing_Spend', 'Google_Spend', 'Meta_Spend', 'Reddit_Spend', 'Snapchat_Spend', 'StackAdapt_Spend', 'Tiktok_Spend']])\n",
    "\n",
    "regression_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Basic OLS Regression</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(regression_df['total_quantity'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(regression_df['total_quantity'].mean())\n",
    "print(regression_df['total_quantity'].var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.formula.api import ols\n",
    "\n",
    "regression_df['interaction'] = regression_df['dma_split'] * regression_df['time_post']\n",
    "\n",
    "model = ols('total_quantity ~ dma_split + time_post + interaction + seasonality + submitter_category_New_Submitter + submitter_category_Reactivated_Submitter + Bing_Spend + Google_Spend + Meta_Spend + Reddit_Spend + Snapchat_Spend + StackAdapt_Spend + Tiktok_Spend', data=regression_df).fit()\n",
    "print(model.summary())\n",
    "print(model.aic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "\n",
    "stats.probplot(model.resid, dist=\"norm\", plot=plt)\n",
    "plt.title('OLS Linear Regression Residuals')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Negative Binomial Modeling</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "y = regression_df['total_quantity']\n",
    "X = sm.add_constant(regression_df[['dma_split', 'time_post', 'interaction', 'seasonality', 'submitter_category_New_Submitter', 'submitter_category_Reactivated_Submitter', 'Bing_Spend', 'Google_Spend', 'Meta_Spend', 'Reddit_Spend', 'Snapchat_Spend', 'StackAdapt_Spend', 'Tiktok_Spend']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = np.linspace(0.01, 2, 10)  # Test a range of alpha values\n",
    "aic_values = [\n",
    "    sm.GLM(y, X, family=sm.families.NegativeBinomial(alpha=alpha)).fit().aic\n",
    "    for alpha in alphas\n",
    "]\n",
    "initial_alpha = alphas[np.argmin(aic_values)] \n",
    "\n",
    "initial_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "def aic_objective_function(alpha, y, X):\n",
    "    alpha = max(0.01, abs(alpha))\n",
    "    try:\n",
    "        model = sm.GLM(y, X, family=sm.families.NegativeBinomial(alpha=alpha)).fit()\n",
    "        print(model.aic)\n",
    "        return model.aic\n",
    "    except:\n",
    "        return np.inf\n",
    "\n",
    "initial_alpha = 0.23\n",
    "result = minimize(aic_objective_function, initial_alpha, args=(y, X), method='L-BFGS-B', bounds=[(0.01, None)])\n",
    "\n",
    "optimal_alpha = result.x[0]\n",
    "\n",
    "print(optimal_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = sm.GLM(y, X, family=sm.families.NegativeBinomial(alpha=optimal_alpha))\n",
    "result = model2.fit(cov_type=\"HC1\")\n",
    "\n",
    "print(result.summary())\n",
    "print(result.aic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Statistical Power Testing</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_counts = regression_df.groupby(['time_post', 'dma_split', 'submitter_category']).size().reset_index(name='count')\n",
    "print(group_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_counts['proportion'] = group_counts['count'] / group_counts['count'].sum()\n",
    "print(group_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.power import TTestIndPower\n",
    "\n",
    "treated_post = regression_df[(regression_df['dma_split'] == 1) & (regression_df['time_post'] == 1)]\n",
    "n_treated_post = len(treated_post)\n",
    "print(n_treated_post)\n",
    "\n",
    "analysis = TTestIndPower()\n",
    "effect_size = result.params['interaction'] / result.bse['interaction']\n",
    "alpha = 0.05\n",
    "power = 0.8\n",
    "\n",
    "# Power for subgroup\n",
    "subgroup_power = analysis.solve_power(effect_size=effect_size, alpha=alpha, nobs1=n_treated_post, ratio=1)\n",
    "print(f\"Power for treated post-treatment group: {subgroup_power:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "effect_size = result.params['interaction'] / np.sqrt(result.bse['interaction'])\n",
    "alpha = 0.05\n",
    "power = 0.8\n",
    "n_obs = len(regression_df)\n",
    "\n",
    "# Power calculation\n",
    "analysis = TTestIndPower()\n",
    "sample_size = analysis.solve_power(effect_size=effect_size, alpha=alpha, power=power, ratio=1)\n",
    "print(f\"Required sample size for 80% power: {sample_size:.0f}\")\n",
    "print(f\"Current sample size: {n_obs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treated_post = regression_df[(regression_df['dma_split'] == 1) & (regression_df['time_post'] == 1)]\n",
    "n_treated_post = len(treated_post)\n",
    "print(f\"Number of treated samples post-treatment: {n_treated_post}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treated_proportion = len(regression_df[regression_df['dma_split'] == 1]) / len(regression_df)\n",
    "post_treatment_proportion = len(regression_df[regression_df['time_post'] == 1]) / len(regression_df)\n",
    "\n",
    "# Estimated required treated post-treatment size\n",
    "required_treated_post = sample_size * treated_proportion * post_treatment_proportion\n",
    "print(f\"Required treated post-treatment sample size: {required_treated_post:.0f}\")\n",
    "print(f\"Actual treated post-treatment sample size: {n_treated_post}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Heteroskedacisity Check</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(result.fittedvalues, result.resid_response, alpha=0.6)\n",
    "plt.axhline(0, color=\"red\", linestyle=\"--\")\n",
    "plt.xlabel(\"Fitted Values (Predicted Mean)\")\n",
    "plt.ylabel(\"Residuals (Response)\")\n",
    "plt.title(\"Residuals vs Fitted Values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.diagnostic import het_breuschpagan\n",
    "\n",
    "exog = result.model.exog  # Predictors (X)\n",
    "bp_test = het_breuschpagan(result.resid_response, exog)\n",
    "\n",
    "bp_stat, bp_pval, _, _ = bp_test\n",
    "print(f\"Breusch-Pagan Test Statistic: {bp_stat}\")\n",
    "print(f\"p-value: {bp_pval}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Bayesian Modeling</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import pymc as pm\n",
    "import arviz as az\n",
    "\n",
    "test_group = regression_df['dma_split'].values  # Top-level group (treatment/control)\n",
    "submitter_groups = regression_df['submitter_category'].astype('category').cat.codes.values\n",
    "\n",
    "with pm.Model() as model:\n",
    "    # Priors for global effects\n",
    "    intercept = pm.Normal(\"Intercept\", mu=0, sigma=10)\n",
    "    global_treatment_effect_beta = pm.Normal(\"Global_Treatment_Effect\", mu=0, sigma=2)\n",
    "    test_group_baseline_beta = pm.Normal(\"Test_Group_Baseline_Effect\", mu=0, sigma=2, shape=len(np.unique(test_group)))  # Treatment/control group baseline effect\n",
    "    time_post_beta = pm.Normal(\"Time_Post_Effect\", mu=0, sigma=2)\n",
    "    \n",
    "    # Hierarchical structure for subcategories\n",
    "    submitter_category_effect_beta = pm.Normal(\"Submitter_Category_Baseline_Effect\", mu=0, sigma=1, shape=len(np.unique(submitter_groups)))\n",
    "    submitter_category_treatment_effect_beta = pm.Normal(\"Submitter_Category_Treatment_Effect\", mu=0, sigma=1, shape=len(np.unique(submitter_groups)))\n",
    "    \n",
    "    # Priors for fixed effects\n",
    "    seasonality_effect_beta = pm.Normal(\"Seasonality_Effect\", mu=0, sigma=2)\n",
    "    bing_spend_beta = pm.LogNormal(\"Bing_Spend_Effect\", mu=0, sigma=2)\n",
    "    google_spend_beta = pm.LogNormal(\"Google_Spend_Effect\", mu=0, sigma=2)\n",
    "\n",
    "    alpha_meta_spend = pm.HalfNormal(\"Alpha_Param_Meta_Spend\", sigma=2)\n",
    "    beta_meta_spend = pm.HalfNormal(\"Beta_Param_Meta_Spend\", sigma=1)\n",
    "    meta_spend_beta = pm.Beta(\"Meta_Spend_Effect\", alpha=alpha_meta_spend, beta=beta_meta_spend)\n",
    "\n",
    "    reddit_spend_beta = pm.Normal(\"Reddit_Spend_Effect\", mu=0, sigma=2)\n",
    "    snapchat_spend_beta = pm.LogNormal(\"Snapchat_Spend_Effect\", mu=0, sigma=2)\n",
    "    stackadapt_spend_beta = pm.LogNormal(\"StackAdapt_Spend_Effect\", mu=0, sigma=2)\n",
    "    tiktok_spend_beta = pm.LogNormal(\"TikTok_Spend_Effect\", mu=0, sigma=2)\n",
    "\n",
    "    neg_binom_alpha = pm.Exponential(\"Alpha_Param - Negative Binomial\", 1.0)\n",
    "\n",
    "    interaction = regression_df['interaction'].to_numpy()\n",
    "\n",
    "    mu = pm.math.exp(\n",
    "        intercept\n",
    "        + test_group_baseline_beta[test_group]\n",
    "        + global_treatment_effect_beta * interaction\n",
    "        + submitter_category_effect_beta[submitter_groups]  # Subcategory effect\n",
    "        + submitter_category_treatment_effect_beta[submitter_groups] * interaction  # Subcategory-specific treatment effect\n",
    "        + seasonality_effect_beta * regression_df['seasonality'].values # Fixed seasonality effect\n",
    "        + time_post_beta * regression_df['time_post'].values\n",
    "        + bing_spend_beta * regression_df['Bing_Spend'].values\n",
    "        + google_spend_beta * regression_df['Google_Spend'].values\n",
    "        + meta_spend_beta * regression_df['Meta_Spend'].values\n",
    "        + reddit_spend_beta * regression_df['Reddit_Spend'].values\n",
    "        + snapchat_spend_beta * regression_df['Snapchat_Spend'].values\n",
    "        + stackadapt_spend_beta * regression_df['StackAdapt_Spend'].values\n",
    "        + tiktok_spend_beta * regression_df['Tiktok_Spend'].values\n",
    "    )\n",
    "\n",
    "    # Negative Binomial likelihood\n",
    "    y_obs = pm.NegativeBinomial(\"y_obs\", mu=mu, alpha=neg_binom_alpha, observed=regression_df['total_quantity'].values)\n",
    "\n",
    "    trace = pm.sample(2000, tune=1000, target_accept=0.95, return_inferencedata=True, cores=4, chains=4, random_seed=42)\n",
    "    log_likelihood = pm.compute_log_likelihood(trace)\n",
    "\n",
    "idata = az.convert_to_inference_data(trace, log_likelihood=log_likelihood)\n",
    "\n",
    "summary = az.summary(trace, hdi_prob=0.95)\n",
    "\n",
    "summary = summary.rename(index={'Test_Group_Baseline_Effect[0]': 'Baseline Group A (Control) Effect', 'Test_Group_Baseline_Effect[1]': 'Baseline Group B (Treated) Effect',\n",
    "                               'Submitter_Category_Baseline_Effect[0]': 'Baseline New Submitter Effect', 'Submitter_Category_Baseline_Effect[1]': 'Baseline Reactivated Submitter Efect',\n",
    "                               'Submitter_Category_Baseline_Effect[2]': 'Baseline Repeat Submitter Effect', 'Submitter_Category_Treatment_Effect[0]': 'New Submitter Treatment Effect',\n",
    "                               'Submitter_Category_Treatment_Effect[1]': 'Reactivated Submitter Treatment Effect',\n",
    "                               'Submitter_Category_Treatment_Effect[2]': 'Repeat Submitter Treatment Effect',\n",
    "                               'Seasonality_Effect': 'Seasonality Effect'})\n",
    "\n",
    "summary['interval_width'] = abs(summary['hdi_2.5%'] - summary['hdi_97.5%'])\n",
    "\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print(trace.posterior[\"Test_Group_Baseline_Effect\"].shape)\n",
    "\n",
    "group_a_effect = trace.posterior[\"Test_Group_Baseline_Effect\"][:, :, 0].values.flatten()\n",
    "group_b_effect = trace.posterior[\"Test_Group_Baseline_Effect\"][:, :, 1].values.flatten()\n",
    "\n",
    "interaction_effect = trace.posterior[\"Global_Treatment_Effect\"].values.flatten()\n",
    "\n",
    "group_a_before = group_a_effect\n",
    "group_a_after = group_a_effect + interaction_effect\n",
    "\n",
    "group_b_before = group_b_effect\n",
    "group_b_after = group_b_effect + interaction_effect\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "sns.kdeplot(group_a_before, label=\"Group A Before Treatment\", fill=True, alpha=0.5)\n",
    "sns.kdeplot(group_b_before, label=\"Group B Before Treatment\", fill=True, alpha=0.5)\n",
    "\n",
    "plt.xlabel(\"Effect Size\", fontsize=14)\n",
    "plt.ylabel(\"Density\", fontsize=14)\n",
    "plt.title(\"Posterior Distributions: Group A and B (Before Treatment)\", fontsize=16)\n",
    "plt.legend(loc=\"best\", fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "sns.kdeplot(group_a_after, label=\"Group A After Treatment\", fill=True, alpha=0.5)\n",
    "sns.kdeplot(group_b_after, label=\"Group B After Treatment\", fill=True, alpha=0.5)\n",
    "\n",
    "plt.xlabel(\"Effect Size\", fontsize=14)\n",
    "plt.ylabel(\"Density\", fontsize=14)\n",
    "plt.title(\"Posterior Distributions: Group A and B (After Treatment)\", fontsize=16)\n",
    "plt.legend(loc=\"best\", fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "effects = trace.posterior[\"Submitter_Category_Treatment_Effect\"]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "for i, group_name in enumerate([\"New Submitter\", \"Reactivated Submitter\", \"Repeat Submitter\"]):\n",
    "    sns.kdeplot(\n",
    "        effects.sel(Submitter_Category_Treatment_Effect_dim_0=i).values.flatten(),\n",
    "        label=f\"{group_name}\",\n",
    "        fill=True,\n",
    "    )\n",
    "\n",
    "plt.axvline(0, color=\"black\", linestyle=\"--\", linewidth=1, label=\"No Effect\")\n",
    "plt.xlabel(\"Treatment Effect\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.title(\"Posterior Distributions of Treatment Effects\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_posterior(trace, var_names=[\"Submitter_Category_Treatment_Effect\"], hdi_prob=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "effects_means = trace.posterior[\"Submitter_Category_Treatment_Effect\"].mean(dim=[\"chain\", \"draw\"]).values\n",
    "effects_hdi = az.hdi(trace, var_names=[\"Submitter_Category_Treatment_Effect\"], hdi_prob=0.95)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "for i, group_name in enumerate([\"New Submitter\", \"Reactivated Submitter\", \"Repeat Submitter\"]):\n",
    "    hdi_lower = effects_hdi[\"Submitter_Category_Treatment_Effect\"].sel(Submitter_Category_Treatment_Effect_dim_0=i)[\"hdi_2.5%\"]\n",
    "    hdi_upper = effects_hdi[\"Submitter_Category_Treatment_Effect\"].sel(Submitter_Category_Treatment_Effect_dim_0=i)[\"hdi_97.5%\"]\n",
    "    plt.errorbar(\n",
    "        effects_means[i],\n",
    "        i,\n",
    "        xerr=[[effects_means[i] - hdi_lower], [hdi_upper - effects_means[i]]],\n",
    "        fmt=\"o\",\n",
    "        label=f\"{group_name}\",\n",
    "    )\n",
    "\n",
    "plt.axvline(0, color=\"black\", linestyle=\"--\", label=\"No Effect\")\n",
    "plt.xlabel(\"Treatment Effect\")\n",
    "plt.yticks(range(len([\"New Submitter\", \"Reactivated Submitter\", \"Repeat Submitter\"])), [\"New Submitter\", \"Reactivated Submitter\", \"Repeat Submitter\"])\n",
    "plt.title(\"Treatment Effects with Credible Intervals\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Model Diagnostics</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waic = az.waic(trace)\n",
    "print(waic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Posterior predictive plots compare model predictions to observed data and can include treatment effects implicitly.\n",
    "\n",
    "ppc = pm.sample_posterior_predictive(trace, model=model)\n",
    "idata.extend(pm.sample_posterior_predictive(trace, model=model, return_inferencedata=True))\n",
    "az.plot_ppc(idata, figsize=(8, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\tConsider plotting residuals (observed - predicted) to identify systematic deviations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "psa_segment_test_pymc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
